{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from numpy import array, ones, zeros, multiply\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HMM:\n",
    "        def __init__(self, state_list, observation_list,\n",
    "                 transition_proba = None,\n",
    "                 observation_proba = None,\n",
    "                 initial_state_proba = None, smoothing_obs = 0.01):\n",
    "          \n",
    "            print \"HMM creating with: \"\n",
    "            self.N = len(state_list)       # number of states\n",
    "            self.M = len(observation_list) # number of possible emissions\n",
    "            print str(self.N)+\" states\"\n",
    "            print str(self.M)+\" observations\"\n",
    "            \n",
    "            UNKid = self.M+1;  \n",
    "            \n",
    "            self.omega_Y = state_list\n",
    "            self.omega_Y.append(\"*\")\n",
    "            self.omega_X = observation_list\n",
    "            \n",
    "            if transition_proba is None:\n",
    "                self.transition_proba = zeros( (self.N+1, self.N+1, self.N), float) \n",
    "            else:\n",
    "                self.transition_proba=transition_proba\n",
    "            if observation_proba is None:\n",
    "                self.observation_proba = zeros( (self.M+1, self.N), float) \n",
    "            else:\n",
    "                self.observation_proba=observation_proba\n",
    "\n",
    "            self.make_indexes() \n",
    "            self.smoothing_obs = smoothing_obs \n",
    "            \n",
    "        def make_indexes(self):\n",
    "            \"\"\"Creates the reverse table that maps states/observations names\n",
    "            to their index in the probabilities array\"\"\"\n",
    "            self.Y_index = {}\n",
    "            for i in range(self.N+1):\n",
    "                self.Y_index[self.omega_Y[i]] = i\n",
    "                \n",
    "            self.X_index = {}\n",
    "            for i in range(self.M):\n",
    "                self.X_index[self.omega_X[i]] = i\n",
    "      \n",
    "        def get_observationIndices( self, observations ):\n",
    "            \"\"\"return observation indices, i.e \n",
    "            return [self.O_index[o] for o in observations]\n",
    "            and deals with OOVs  \n",
    "            \"\"\"\n",
    "            indices = zeros( len(observations), int )\n",
    "            k = 0\n",
    "            for o in observations:\n",
    "                if o in self.X_index:\n",
    "                    indices[k] = self.X_index[o]\n",
    "                else:\n",
    "                    indices[k] = UNKid\n",
    "                k += 1\n",
    "            return indices\n",
    "    \n",
    "        def data2indices(self, sent): \n",
    "            \"\"\"From a word of the corpus: \n",
    "            - extract the letter and coorection \n",
    "            - returns two list of indices, one for each\n",
    "            -> (letterid, correctionid)\n",
    "            \"\"\"\n",
    "            letterids = list()\n",
    "            correctionids  = list()\n",
    "            for couple in sent:\n",
    "                ltr = couple[0]\n",
    "                crt = couple[1]\n",
    "                letterids.append(self.X_index[ltr])\n",
    "                correctionids.append(self.Y_index[crt])\n",
    "            return letterids,correctionids\n",
    "            \n",
    "        def observation_estimation(self, pair_counts):\n",
    "\n",
    "            for pair in pair_counts:\n",
    "                letter=pair[0]\n",
    "                correction=pair[1]\n",
    "                count=pair_counts[pair]\n",
    "                \n",
    "                if letter in self.X_index:\n",
    "                    k=self.X_index[letter]\n",
    "                i=self.Y_index[correction]\n",
    "                self.observation_proba[k,i]=count\n",
    "            self.observation_proba=self.observation_proba+self.smoothing_obs\n",
    "            self.observation_proba=self.observation_proba/self.observation_proba.sum(axis=0).reshape(1, self.N)\n",
    "                        \n",
    "        def transition_estimation(self, c_bitag, c_tritag):\n",
    "            \n",
    "            for tritag in c_tritag:\n",
    "                #getting indices\n",
    "                y_2=self.Y_index[tritag[0]]\n",
    "                y_1=self.Y_index[tritag[1]]\n",
    "                y=self.Y_index[tritag[2]]\n",
    "                bigram=(tritag[0],tritag[1])       \n",
    "                self.transition_proba[y_2,y_1,y]=float(c_tritag[tritag])/float(c_bitag[bigram])               \n",
    "   \n",
    "        def init_estimation(self, c_inits, c_inits_bitag):\n",
    "            somme=float(sum(c_inits.values()))\n",
    "            for correction in c_inits:\n",
    "                i=self.Y_index[correction]\n",
    "                j=self.Y_index[\"*\"]\n",
    "                self.transition_proba[j,j,i]=float(c_inits[correction])/somme\n",
    "                \n",
    "            for pair in c_inits_bitag:\n",
    "                y_1=self.Y_index[pair[0]]\n",
    "                y=self.Y_index[pair[1]]\n",
    "                j=self.Y_index[\"*\"]\n",
    "                self.transition_proba[j,y_1,y]=float(c_inits_bitag[pair])/float(c_inits[pair[0]])\n",
    "                \n",
    "            \n",
    "        def supervised_training_ME(self, pair_counts, c_bitag, c_tritag ,c_inits, c_inits_bitag):\n",
    "            \"\"\" Train the HMM's parameters. This function wraps everything\"\"\"\n",
    "            self.observation_estimation(pair_counts)\n",
    "            self.transition_estimation(c_bitag, c_tritag)\n",
    "            self.init_estimation(c_inits, c_inits_bitag)\n",
    "            \n",
    "        \n",
    "        def supervised_training_perceptron(self, T, data):\n",
    "            #Set initially parameters\n",
    "   \n",
    "            #self.transition_proba = np.zeros( (self.N+1, self.N+1, self.N), float)\n",
    "            #self.observation_proba = np.zeros( (self.M+1, self.N), float)\n",
    "\n",
    "            #self.transition_proba = np.ones( (self.N+1, self.N+1, self.N), float)\n",
    "            #self.observation_proba = np.ones( (self.M+1, self.N), float)\n",
    "    \n",
    "    \n",
    "            for iteration in range(T):\n",
    "                for observations in data:\n",
    "                    if len(observations) > 1:\n",
    "                        prob, predicted_tags = self.viterbi(observations)\n",
    "                        count_pair, count_tritag, count_tritag_predicted, count_pair_predicted = make_counts_each_observation_sequence(observations, predicted_tags)\n",
    "\n",
    "                        for tritag in count_tritag:\n",
    "                            c1 = count_tritag.get(tritag)\n",
    "                            if count_tritag_predicted.has_key(tritag):\n",
    "                                c2 = count_tritag_predicted.get(tritag)\n",
    "                            else:\n",
    "                                c2 = 0\n",
    "                    \n",
    "                            self.transition_proba[ self.Y_index[tritag[0]], self.Y_index[tritag[1]], self.Y_index[tritag[2]] ] = self.transition_proba[ self.Y_index[tritag[0]], self.Y_index[tritag[1]], self.Y_index[tritag[2]] ] + c1 - c2 \n",
    "                \n",
    "                        for pair in count_pair:\n",
    "                            c1 = count_pair.get(pair)\n",
    "                            if count_pair_predicted.has_key(pair):\n",
    "                                c2 = count_pair_predicted.get(pair)\n",
    "                            else:\n",
    "                                c2 = 0\n",
    "                    \n",
    "                            self.observation_proba[self.X_index[pair[0]],self.Y_index[pair[1]] ] = self.observation_proba[self.X_index[pair[0]],self.Y_index[pair[1]] ] + c1 - c2\n",
    "                        \n",
    "        \n",
    "        def get_possible_corrections(self,k):\n",
    "            if k == -1:\n",
    "                return set(['*'])\n",
    "            if k == 0:\n",
    "                return set(['*'])\n",
    "            else:\n",
    "                return self.omega_Y[:-1]\n",
    "\n",
    "        def get_letter(self,word,k):\n",
    "            if k < 0:\n",
    "                return '*'\n",
    "            else:\n",
    "                return word[k][0]\n",
    "    \n",
    "            \n",
    "        def viterbi(self,word):\n",
    "            \n",
    "            \n",
    "            V = {}\n",
    "            path = {}\n",
    "            # init\n",
    "            V[0,'*','*'] = 1\n",
    "            path['*','*'] = []\n",
    "            \n",
    "            for k in range(1,len(word)+1):\n",
    "                temp_path = {}\n",
    "                letter = self.X_index[self.get_letter(word,k-1)]\n",
    "                \n",
    "                for u in self.get_possible_corrections(k-1):\n",
    "                    \n",
    "                    for v in self.get_possible_corrections(k):\n",
    "\n",
    "                        i_u=self.Y_index[u]\n",
    "                        i_v=self.Y_index[v]\n",
    "                        \n",
    "                        V[k,u,v],backpointer = max([(V[k-1,w,u] * \n",
    "                                                     self.transition_proba[self.Y_index[w],i_u,i_v] * \n",
    "                                                     self.observation_proba[letter,i_v],w) \n",
    "                                                    for w in self.get_possible_corrections(k-2)])                       \n",
    "                        \n",
    "                        temp_path[u,v] = path[backpointer,u] + [v]                        \n",
    "                path = temp_path\n",
    "                 \n",
    "            prob,maxu,maxv= max([(V[k,u,v],u,v) for u in self.omega_Y[0:26] for v in self.omega_Y[0:26]])\n",
    "                \n",
    "            return prob, path[maxu,maxv]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_counts(corpus):\n",
    "    \"\"\" \n",
    "    Build different count tables to train a HMM. Each count table is a dictionnary. \n",
    "    Returns: \n",
    "    * c_letter: letter counts\n",
    "    * c_correction: correction counts\n",
    "    * c_pairs: count of pairs (letter,correction)\n",
    "    \n",
    "    * c_bitag: count of tag bigram \n",
    "    * c_tritag: count of tag trigram \n",
    "    * c_inits: count of tag found in the first position\n",
    "    \n",
    "    \"\"\"\n",
    "    c_letter = dict()\n",
    "    c_correction = dict()\n",
    "    c_pairs= dict()\n",
    "    c_bitag = dict()\n",
    "    c_tritag = dict()\n",
    "    c_inits = dict()\n",
    "    c_inits_bitag = dict()\n",
    "    \n",
    "    for word in corpus:\n",
    "        for i in range(len(word)):\n",
    "            couple= word[i]\n",
    "            letter = couple[0]\n",
    "            correction = couple[1]\n",
    "            #Counting letter \n",
    "            if letter in c_letter:\n",
    "                c_letter[letter] +=1\n",
    "            else:\n",
    "                c_letter[letter] =1  \n",
    "            #Counting correction\n",
    "            if correction in c_correction:\n",
    "                c_correction[correction] +=1\n",
    "            else:\n",
    "                c_correction[correction] =1\n",
    "            #Counting par(letter, correction)\n",
    "            if couple in c_pairs:\n",
    "                c_pairs[couple] +=1\n",
    "            else :\n",
    "                c_pairs[couple] =1\n",
    "            #Counting bitag(corr_i, corr_(i+1))\n",
    "            if i > 0 and i < len(word)-1:\n",
    "                bitag = (word[i-1][1], correction)\n",
    "                if bitag in c_bitag:\n",
    "                    c_bitag[bitag] += 1\n",
    "                else:\n",
    "                    c_bitag[bitag] =1\n",
    "                    \n",
    "            #Counting tritag\n",
    "            if i > 1:\n",
    "                tritag = (word[i-2][1],word[i-1][1], correction)\n",
    "                if tritag in c_tritag :\n",
    "                    c_tritag[tritag] +=1\n",
    "                else :\n",
    "                    c_tritag[tritag] =1\n",
    "                    \n",
    "            if i == 0 and len(word)>1:\n",
    "                if correction in c_inits:\n",
    "                    c_inits[correction] +=1\n",
    "                else :\n",
    "                    c_inits[correction] =1\n",
    "                bg_first=(correction,word[i+1][1])\n",
    "                \n",
    "                if bg_first in c_inits_bitag:\n",
    "                    c_inits_bitag[bg_first]+=1\n",
    "                else:\n",
    "                    c_inits_bitag[bg_first]=1\n",
    "                    \n",
    "    return c_letter, c_correction, c_pairs, c_bitag, c_tritag, c_inits, c_inits_bitag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_counts_each_observation_sequence(observations, predicted_tags):\n",
    "    count_pair = dict()\n",
    "    count_bitag = dict()\n",
    "    count_tritag = dict()\n",
    "    \n",
    "    count_tritag_predicted = dict()\n",
    "    count_pair_predicted = dict()\n",
    "\n",
    "    for i in range(len(observations)):\n",
    "        pair = observations[i]\n",
    "        observation = pair[0]\n",
    "        tag = pair[1]\n",
    "            \n",
    "        #Counting pair(observation, tag)\n",
    "        if pair in count_pair:\n",
    "            count_pair[pair] += 1\n",
    "        else :\n",
    "            count_pair[pair] = 1\n",
    "            \n",
    "\n",
    "        #Counting tritag(tag_(i-2), tag_(i-1), tag_i)\n",
    "        if i > 1:\n",
    "            tritag = (observations[i-2][1],observations[i-1][1], tag)\n",
    "            if tritag in count_tritag :\n",
    "                count_tritag[tritag] += 1\n",
    "            else :\n",
    "                count_tritag[tritag] = 1\n",
    "        \n",
    "        \n",
    "        #Counting predicted pair\n",
    "        predicted_pair = (observation, predicted_tags[i])\n",
    "        \n",
    "        if predicted_pair in count_pair_predicted:\n",
    "            count_pair_predicted[predicted_pair] += 1\n",
    "        else :\n",
    "            count_pair_predicted[predicted_pair] = 1\n",
    "        \n",
    "        \n",
    "        #Counting predicted tritag(tag_(i-2), tag_(i-1), tag_i)\n",
    "        tag_predicted = predicted_tags[i]\n",
    "        if i > 1:\n",
    "            tritag_predicted = (predicted_tags[i-2],predicted_tags[i-1], tag_predicted)\n",
    "            if tritag_predicted in count_tritag_predicted :\n",
    "                count_tritag_predicted[tritag_predicted] += 1\n",
    "            else :\n",
    "                count_tritag_predicted[tritag_predicted] = 1\n",
    "\n",
    "    return count_pair, count_tritag, count_tritag_predicted, count_pair_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data and making counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "train10=pickle.load( open( \"./typos-data/train10.pkl\", \"rb\" ))\n",
    "test10=pickle.load( open( \"./typos-data/test10.pkl\", \"rb\" ))\n",
    "train20=pickle.load( open( \"./typos-data/train20.pkl\", \"rb\" ))\n",
    "test20=pickle.load( open( \"./typos-data/test20.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c_letter, c_correction, c_pairs, c_bitag, c_tritag, c_inits, c_inits_bitag=make_counts(train10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the HMM and supervised training ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HMM creating with: \n",
      "26 states\n",
      "26 observations\n"
     ]
    }
   ],
   "source": [
    "hmm = HMM(state_list=c_correction.keys(), observation_list=c_letter.keys(),\n",
    "                 transition_proba = None,\n",
    "                 observation_proba = None,\n",
    "                 initial_state_proba = None)\n",
    "hmm.supervised_training_ME( c_pairs, c_bitag, c_tritag ,c_inits, c_inits_bitag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised training perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Change self.transition_proba and self.observation_proba\n",
    "hmm.supervised_training_perceptron(1,train10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the HMM ME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wrong_words=[]\n",
    "true_words=[] #denotes all underlying hidden states\n",
    "for sent in test10:\n",
    "    data_test = np.asarray(sent)\n",
    "    obs,states = np.hsplit(data_test,2)\n",
    "    wrong_words.append(obs.tostring())\n",
    "    true_words.append(list(states.tostring()))\n",
    "wrong_words = np.array(wrong_words)\n",
    "true_words = np.array(true_words)   #These are the true lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v', 'i', 'o', 'l', 'e', 'n', 'v', 'e']\n"
     ]
    }
   ],
   "source": [
    "word = wrong_words[-1]\n",
    "p,v = hmm.viterbi(word)\n",
    "print v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "correction_words=[]\n",
    "for word in wrong_words:\n",
    "    if(len(word)>1):\n",
    "        p,v=hmm.viterbi(word)\n",
    "    else:\n",
    "        v=list(word)\n",
    "    correction_words.append(v)\n",
    "correction_words=np.array(correction_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_error(correction_words,true_words):\n",
    "    \"\"\"Compares the corrections and true_vals\"\"\"\n",
    "    error=0\n",
    "    total=0\n",
    "    for f, b in zip(correction_words, true_words):\n",
    "        if cmp(f,b)!=0:\n",
    "            for i in range(len(f)):\n",
    "                if f[i]!=b[i]:\n",
    "                    error+=1\n",
    "        total+=len(f)\n",
    "\n",
    "    return float(error)/float(total)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0405737704918\n"
     ]
    }
   ],
   "source": [
    "print compute_error(correction_words,true_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
